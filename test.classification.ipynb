{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: READING AND PROCESSING DATA\n",
    "Dataset used: https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/crop.rec.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = list(set(dataset[\"label\"]))\n",
    "dataset[\"label\"] = dataset[\"label\"].map(lambda x: labels_unique.index(x))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=42)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: FEATURE VISUALISATION/SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    train_dataset[[\"N\", \"K\", \"temperature\", \"humidity\", \"ph\", \"rainfall\"]],\n",
    "    diag_kind=\"kde\",\n",
    ")\n",
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.copy().drop(\"label\", axis=1)\n",
    "X_test = test_dataset.copy().drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_dataset.copy()[\"label\"]\n",
    "Y_test = test_dataset.copy()[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION ###\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "\n",
    "\n",
    "def run_model(MODEL: type):\n",
    "    begin = time.time()\n",
    "\n",
    "    ret = {}\n",
    "\n",
    "    m = MODEL()\n",
    "\n",
    "    m.fit(X_train, Y_train)\n",
    "\n",
    "    ret[\"RMSE\"] = mean_squared_error(m.predict(X_test), Y_test, squared=False)\n",
    "    ret[\"MAE\"] = mean_absolute_error(m.predict(X_test), Y_test)\n",
    "    ret[\"score\"] = m.score(X_test, Y_test)\n",
    "    ret[\"time\"] = time.time() - begin\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 TESTING VARIOUS CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_models = [\n",
    "    SVC,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    DecisionTreeClassifier,\n",
    "]\n",
    "\n",
    "for ModelType in clf_models:\n",
    "    print(f\"> testing model: {ModelType.__name__}\")\n",
    "    scores = run_model(ModelType)\n",
    "    print(f\"  MAE:        {scores['RMSE']}\")\n",
    "    print(f\"  RMSE:       {scores['MAE']}\")\n",
    "    print(f\"  accuracy:   {(scores['score'] * 100) : .{3}}%\")\n",
    "    print(f\"  time taken: {scores['time']:.{3}}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 TESTING REGRESSION MODELS: TODO (DEBUGGING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SOME SETUP ###\n",
    "# we'll predict the pH of the soil\n",
    "\n",
    "X_train = train_dataset.copy().drop(\"ph\", axis=1)\n",
    "X_test = test_dataset.copy().drop(\"ph\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_dataset.copy()[\"ph\"]\n",
    "Y_test = test_dataset.copy()[\"ph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge, ARDRegression\n",
    "\n",
    "rg_models = [\n",
    "    BayesianRidge,\n",
    "    ARDRegression,\n",
    "]\n",
    "\n",
    "for ModelType in rg_models:\n",
    "    print(f\"> testing model: {ModelType.__name__}\")\n",
    "    scores = run_model(ModelType)\n",
    "    print(f\"  MAE:        {scores['RMSE']}\")\n",
    "    print(f\"  RMSE:       {scores['MAE']}\")\n",
    "    print(f\"  accuracy:   {scores['score']}\")\n",
    "    print(f\"  time taken: {scores['time']:.{3}}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Low error but low accuracy, check for bugs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. *Regression* - Fix regression error.\n",
    "2. *LSTM Cell* - Helpful for predicting given a range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTS ###\n",
    "reg = BayesianRidge()\n",
    "\n",
    "reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(X_test), Y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
